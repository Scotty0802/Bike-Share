---
title: "Bike_Share"
format: pdf
editor: visual
---

## Set up

```{r}
#| output: false
#| message: false
library(tidyverse)
library(tidymodels)
library(vroom)
library(ggplot2)
library(dplyr)
library(patchwork)
library(glmnet)
library(rpart)
```

## Import

```{r}
#| output: false
#| message: false

train<- vroom("C:/Users/riley/Desktop/Fall 2025/Stat 348/data/bike-sharing-demand/train.csv")
test <- vroom("C:/Users/riley/Desktop/Fall 2025/Stat 348/data/bike-sharing-demand/test.csv")
```

## Clean

```{r}
train <- train |>
  #mutate(workingday = as.factor(workingday),
   #      holiday = as.factor(holiday)) |>
  #mutate(weather = factor(weather), 
  #                         levels = c("1","2","3","4"),
  #                         labels = c("Clear to Cloudy","Very Cloudy","Percipitation","Heavy Percipitation"))) |>
  # mutate(season = factor(season,
  #                        levels = c("1","2","3","4"),
  #                        labels = c("Spring","Summer","Fall","Winter"))) |>
  select(-casual, -registered)|>
  mutate(count = log(count))
```

## Model Making

```{r}
#Tree Model
model <- decision_tree(tree_depth = tune(),cost_complexity = tune(), 
                            min_n=tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("regression")
```

## Recipe

```{r}
bike_recipe <- recipe(count~., data=train) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |> 
step_mutate(weather = factor(weather)) %>%
step_date(datetime, features="dow") %>% # gets day of week
step_time(datetime, features="hour") %>% #create time variable
step_dummy(all_nominal_predictors()) %>%
step_rm(datetime) %>% 
step_zv(all_predictors())|> #removes zero-variance predictors9
step_lincomb(all_predictors())|>
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(bike_recipe)
```

## Baking (Optional if you are using a workflow)

```{r}
#train_processed <- bake(prepped_recipe, new_data = train)
#test_processed  <- bake(prepped_recipe, new_data = test) 
```

## Workflow

```{r}
wf <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(model)
```

## Tuning

```{r}
## Grid of values to tune over13
tune_grid <- grid_regular(
  tree_depth(range = c(1, 10)),
  cost_complexity(),
  min_n(),
  levels = 5   # number of values per parameter
)

## Split data for CV
folds <- vfold_cv(train, v = 2, repeats = 1)

## Run the CV
param_tune <- tune_grid(
  wf,
  resamples = folds,
  grid = tune_grid,
  metrics = metric_set(rmse, rsq))

## Plot Results (example)
collect_metrics(param_tune) %>% # Gathers metrics into DF
filter(.metric=="rmse") %>%
ggplot(data=., aes(x = tree_depth, y = mean, color = factor(min_n))) +
geom_line() 

## Find Best Tuning Parameters
best_param <- select_best(param_tune, metric="rmse")

## Finalize the Workflow & fit it
final_wf <- wf %>%
finalize_workflow(best_param) %>%
fit(data=train)

```

## Predictions

```{r}
## Predict
#final_wf %>%
#predict(new_data = test)

test_preds <- predict(final_wf, new_data = test)
test_preds <- test_preds |>
  mutate(.pred = exp(.pred))
```

## Kaggle Submission

```{r}

kaggle_submission <- test_preds %>%
bind_cols(., test) %>% 
  select(datetime, .pred) |>
  rename(count=.pred) %>%  
  mutate(count=pmax(0, count)) %>% 
  mutate(datetime=as.character(format(datetime)))
## Write out the file9
vroom_write(x = kaggle_submission, 
            file = "~/GitHub/Stat 348/Bike-Share/Kaggle_Submission.csv", 
            delim = ",")
vroom_write(x = kaggle_submission_tree, 
            file = "~/GitHub/Stat 348/Bike-Share/Kaggle_Submission.csv", 
            delim = ",")
```
