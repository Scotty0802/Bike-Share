---
title: "Bike_Share"
format: pdf
editor: visual
---

## Set up

```{r}
#| output: false
#| message: false
library(tidyverse)
library(tidymodels)
library(vroom)
library(ggplot2)
library(dplyr)
library(patchwork)
library(glmnet)
```

## Import

```{r}
#| output: false
#| message: false

train<- vroom("C:/Users/riley/Desktop/Fall 2025/Stat 348/data/bike-sharing-demand/train.csv")
test <- vroom("C:/Users/riley/Desktop/Fall 2025/Stat 348/data/bike-sharing-demand/test.csv")
```

## Clean

```{r}
train <- train |>
  #mutate(workingday = as.factor(workingday),
   #      holiday = as.factor(holiday)) |>
  #mutate(weather = factor(weather), 
  #                         levels = c("1","2","3","4"),
  #                         labels = c("Clear to Cloudy","Very Cloudy","Percipitation","Heavy Percipitation"))) |>
  # mutate(season = factor(season,
  #                        levels = c("1","2","3","4"),
  #                        labels = c("Spring","Summer","Fall","Winter"))) |>
  select(-casual, -registered)|>
  mutate(count = log(count))
```

## Model Making

```{r}
#lin_model 

preg_model <- linear_reg(penalty=tune(),mixture=tune()) %>% 
set_engine("glmnet")
```

## Recipe

```{r}
bike_recipe <- recipe(count~., data=train) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |> 
step_mutate(weather = factor(weather)) %>%
step_date(datetime, features="dow") %>% # gets day of week
step_time(datetime, features="hour") %>% #create time variable
step_dummy(all_nominal_predictors()) %>%
step_rm(datetime) %>% 
step_zv(all_predictors())|> #removes zero-variance predictors9
step_lincomb(all_predictors())|>
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(bike_recipe)
```

## Baking (Optional if you are using a workflow)

```{r}
train_processed <- bake(prepped_recipe, new_data = train)
test_processed  <- bake(prepped_recipe, new_data = test) 
```

## Workflow

```{r}
preg_wf <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(preg_model)
```

## Tuning
```{r}
## Grid of values to tune over13
grid_of_tuning_params <- grid_regular(penalty(), mixture(), levels = 10) ## L^2 total tuning possibilities

## Split data for CV
folds <- vfold_cv(train, v = 5, repeats = 1)

## Run the CV
CV_results <- preg_wf %>%
tune_grid(resamples=folds,grid=grid_of_tuning_params,metrics=metric_set(rmse, mae)) #Or leave metrics NULL

## Plot Results (example)
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse") %>%
ggplot(data=., aes(x=penalty, y=mean, color=factor(mixture))) +
geom_line()

## Find Best Tuning Parameters
bestTune <- CV_results %>%
select_best(metric="rmse")

## Finalize the Workflow & fit it
final_wf <- preg_wf %>%
finalize_workflow(bestTune) %>%
fit(data=train)



```


## Predictions

```{r}
## Predict
#final_wf %>%
#predict(new_data = test)

test_preds <- predict(final_wf, new_data = test)
test_preds <- test_preds |>
  mutate(.pred = exp(.pred))
```

## Kaggle Submission

```{r}
kaggle_submission <- test_preds %>%
bind_cols(., test) %>% 
  select(datetime, .pred) |>
  rename(count=.pred) %>%  
  mutate(count=pmax(0, count)) %>% 
  mutate(datetime=as.character(format(datetime)))

## Write out the file9
vroom_write(x = kaggle_submission, 
            file = "~/GitHub/Stat 348/Bike-Share/Kaggle_Submission.csv", 
            delim = ",")
```
